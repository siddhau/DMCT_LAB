{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "data = iris[\"data\"]\n",
    "data = StandardScaler().fit_transform(data)\n",
    "labels = iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(data, labels, train_size=0.75,\n",
    "                                                test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NBClassifier(object):\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        self.X = data\n",
    "        self.Y = labels\n",
    "        self.N = self.X.shape[0]\n",
    "        self.M = self.X.shape[1]\n",
    "        self.class_values = np.unique(self.Y)\n",
    "        self.attr_means = np.mean(self.X, axis=0)\n",
    "        self.attr_stdevs = np.std(self.X, axis=0)\n",
    "\n",
    "    def get_gaussian_probability(self, mu, sigma, x):\n",
    "        #write a function that returns the gaussian probability of x given mean as mu and std as sigma.\n",
    "        a=(x-mu)**2\n",
    "        a*=-1.0\n",
    "        b=2.0*sigma*sigma\n",
    "        c=np.exp(a/b)\n",
    "        d=np.sqrt(2*np.pi*sigma)\n",
    "        ans=c/d\n",
    "        return ans\n",
    "        \n",
    "    def get_class_probablity(self, class_value):\n",
    "        # This function computes the probability of a particular\n",
    "        # class label in the train set\n",
    "        loc = np.where(self.Y == class_value)[0]\n",
    "        return len(loc)/self.N\n",
    "\n",
    "    def get_all_class_probabilities(self):\n",
    "        # This function computes the probs. of all classes and returns a list\n",
    "        return [get_class_probability(self.class_values[i]) for i in range(len(self.class_values))]\n",
    "        #You need to write this function\n",
    "\n",
    "    def get_prob_of_value_in_attr(self, data, attr_idx, value):\n",
    "        # Calculates the prob. of a value in an attribute for a given data set\n",
    "        # data - dataset\n",
    "        # attr_idx - The attribute\n",
    "        # value - The value to consider\n",
    "        mu = np.mean(data[:, attr_idx])\n",
    "        sigma = np.std(data[:, attr_idx])\n",
    "        return self.get_gaussian_probability(mu, sigma, value)\n",
    "    \n",
    "    def get_prob_of_tuple(self, t):\n",
    "        # Calculate the prob. of a multi attribute tuple. \n",
    "        #This function considers the entire train set.\n",
    "        return np.prod([clf.get_prob_of_value_in_attr(self.X, i, t[i])\n",
    "                        for i in range(self.M)])\n",
    "\n",
    "    def get_prob_of_tuple_in_class(self, t, class_value):\n",
    "        # This function calculates the prob. of a tuple \n",
    "        # when a class is specified.\n",
    "        locs = np.where(self.Y == class_value)\n",
    "        #Subset of the data belonging to the specified class.\n",
    "        subset = self.X[locs] \n",
    "        return np.prod([clf.get_prob_of_value_in_attr(subset, i, t[i])\n",
    "                        for i in range(self.M)])\n",
    "\n",
    "    def predict(self, t):\n",
    "        # Predicts the most likely class for a tuple taking \n",
    "        #into consideration all classes\n",
    "        class_probs = [self.get_prob_of_tuple_in_class(t, c)\n",
    "                       for c in self.class_values]\n",
    "        # P(C|t) = (P(t|C)*P(C))/P(t)\n",
    "        #Compute the value of class_probs to fit the definition of the Naive Bayesian\n",
    "        indexes = np.argsort(class_probs)\n",
    "        return indexes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = NBClassifier()\n",
    "clf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 2 2 0 0 2 2 2 0 2 1 2 1 2 0 1 2 0 0 2 0 2 2 1 1 2 2 1 1 2 2 2 2 2\n",
      " 1] \n",
      " [1 1 0 1 1 2 0 0 2 2 2 0 2 1 2 1 2 0 1 2 0 0 2 0 1 2 1 1 2 2 1 1 2 2 2 2 2\n",
      " 1]\n",
      "Score =  0.947368421053\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for t in testX:\n",
    "    predictions.append(clf.predict(t))\n",
    "predictions = np.array(predictions).astype(\"int\")\n",
    "print(testY, \"\\n\", predictions)\n",
    "score = accuracy_score(testY, predictions)\n",
    "print(\"Score = \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
